{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21aab74a-bbcc-4671-ab9b-b26dfa1fe5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from keybert import KeyBERT\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import pickle\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bcd600-03fd-4369-8ba3-c694e2dd0384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SemEval dataset\n",
    "sem_eval_ds = load_dataset(\"SemEvalWorkshop/sem_eval_2010_task_8\")\n",
    "\n",
    "# Load Inspec dataset\n",
    "inspec_ds = load_dataset(\"midas/inspec\", \"generation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa1e2df-2fba-4dc6-b835-ac014862603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading KeyBERT with all-mpnet-base-v2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faaef1c37ede40e08e1d1007a1e17b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fc334a4eb442b5b22ab68b0e65e21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ceb763109e045fc9791383f0b5a27f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004f926092564b508f215055176785f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e97313973004989868f71ac6d33d5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01477230e07d43c6811311b0d3f62000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d3588e3c3445e4839e0fc5095c19e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed207f936b0848eaaae3f6d0688401d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0baac391b94282a90fdbf8e613c68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329e503c10734eb2b15f1fbdb2a054fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb0dc6f566f49d39e6bfbf97f6fc068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def clean_sem_eval_sentence(text: str) -> str:\n",
    "    \"\"\"Remove entity XML tags from SemEval sentences.\"\"\"\n",
    "    return re.sub(r'</?e[12]>', '', text).strip()\n",
    "\n",
    "def prepare_inspec_text(tokens: List[str]) -> str:\n",
    "    \"\"\"Convert list of tokens to clean string for Inspec.\"\"\"\n",
    "    return ' '.join([t for t in tokens if not (t.startswith('-') and t.endswith('-'))])\n",
    "\n",
    "def extract_keyphrases(text: str, model: KeyBERT, top_n: int = 8) -> List[str]:\n",
    "    \"\"\"Extract keyphrases using KeyBERT with maxsum.\"\"\"\n",
    "    keyphrases = model.extract_keywords(\n",
    "        text,\n",
    "        keyphrase_ngram_range=(1, 3),\n",
    "        stop_words='english',\n",
    "        top_n=top_n,\n",
    "        use_maxsum=True\n",
    "    )\n",
    "    return [kp[0] for kp in keyphrases]\n",
    "\n",
    "# Initialize KeyBERT with a stronger embedding model\n",
    "print(\"Loading KeyBERT with all-mpnet-base-v2...\")\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "model = KeyBERT(embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb160b77-5296-4766-af35-60004bb37acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_matches(true_phrases: List[str], extracted_phrases: List[str], partial_match: bool = True) -> Tuple[float, float, float]:\n",
    "    \"\"\"Calculate precision, recall, and F1 score with optional partial matching.\"\"\"\n",
    "    if partial_match:\n",
    "        matched_true = set()\n",
    "        matched_extracted = set()\n",
    "        for i, ext in enumerate(extracted_phrases):\n",
    "            for j, true in enumerate(true_phrases):\n",
    "                if ext.lower() in true.lower() or true.lower() in ext.lower():\n",
    "                    matched_extracted.add(i)\n",
    "                    matched_true.add(j)\n",
    "        matches = len(matched_true)\n",
    "    else:\n",
    "        matches = sum(1 for ext in extracted_phrases if any(ext.lower() == true.lower() for true in true_phrases))\n",
    "\n",
    "    precision = matches / len(extracted_phrases) if extracted_phrases else 0\n",
    "    recall = matches / len(true_phrases) if true_phrases else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd27c0f-be7c-4233-8893-609c16782c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sem_eval(dataset, model, top_n=2):\n",
    "    results = []\n",
    "    metrics = []\n",
    "    for sample in tqdm(dataset):\n",
    "        sentence = sample['sentence']\n",
    "        true_entities = re.findall(r'<e[12]>(.*?)</e[12]>', sentence)\n",
    "        clean_text = clean_sem_eval_sentence(sentence)\n",
    "        extracted = extract_keyphrases(clean_text, model, top_n=top_n)\n",
    "\n",
    "        precision, recall, f1 = evaluate_matches(true_entities, extracted)\n",
    "        metrics.append((precision, recall, f1))\n",
    "\n",
    "        results.append({\n",
    "            'sentence': sentence,\n",
    "            'true_entities': true_entities,\n",
    "            'extracted_phrases': extracted,\n",
    "            'metrics': {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "        })\n",
    "    avg_metrics = {\n",
    "        'precision': np.mean([m[0] for m in metrics]),\n",
    "        'recall': np.mean([m[1] for m in metrics]),\n",
    "        'f1': np.mean([m[2] for m in metrics]),\n",
    "    }\n",
    "    return results, avg_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8504a1-8646-4847-a327-d4204c4b7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_inspec(dataset, model, top_n=8):\n",
    "    results = []\n",
    "    metrics = []\n",
    "    for sample in tqdm(dataset):\n",
    "        text = prepare_inspec_text(sample['document'])\n",
    "        true_keyphrases = sample['extractive_keyphrases']\n",
    "        extracted = extract_keyphrases(text, model, top_n=top_n)\n",
    "\n",
    "        precision, recall, f1 = evaluate_matches(true_keyphrases, extracted)\n",
    "        metrics.append((precision, recall, f1))\n",
    "\n",
    "        results.append({\n",
    "            'document': sample['document'],\n",
    "            'true_keyphrases': true_keyphrases,\n",
    "            'extracted_phrases': extracted,\n",
    "            'metrics': {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "        })\n",
    "    avg_metrics = {\n",
    "        'precision': np.mean([m[0] for m in metrics]),\n",
    "        'recall': np.mean([m[1] for m in metrics]),\n",
    "        'f1': np.mean([m[2] for m in metrics]),\n",
    "    }\n",
    "    return results, avg_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f183c9b-4550-4515-8a8d-4dbefe650186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SemEval-2010 train dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47d31c4323140339e079f005900112d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SemEval-2010 test dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e546f8fc50f4b05b9620244a6a4a5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SemEval-2010 Metrics:\n",
      "Train - Precision: 0.524, Recall: 0.524, F1: 0.524\n",
      "Test  - Precision: 0.529, Recall: 0.529, F1: 0.529\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing SemEval-2010 train dataset...\")\n",
    "sem_eval_train_results, sem_eval_train_metrics = process_sem_eval(sem_eval_ds['train'], model, top_n=2)\n",
    "\n",
    "print(\"Processing SemEval-2010 test dataset...\")\n",
    "sem_eval_test_results, sem_eval_test_metrics = process_sem_eval(sem_eval_ds['test'], model, top_n=2)\n",
    "\n",
    "print(\"\\nSemEval-2010 Metrics:\")\n",
    "print(f\"Train - Precision: {sem_eval_train_metrics['precision']:.3f}, Recall: {sem_eval_train_metrics['recall']:.3f}, F1: {sem_eval_train_metrics['f1']:.3f}\")\n",
    "print(f\"Test  - Precision: {sem_eval_test_metrics['precision']:.3f}, Recall: {sem_eval_test_metrics['recall']:.3f}, F1: {sem_eval_test_metrics['f1']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "029cc84f-04f5-4021-80a3-7e003cf5691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Inspec train dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e59764c74f4e69b2a7b68d32ac1b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Inspec test dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771045670e4541939882bbfc26935e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inspec Metrics:\n",
      "Train - Precision: 0.284, Recall: 0.422, F1: 0.313\n",
      "Test  - Precision: 0.295, Recall: 0.425, F1: 0.321\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing Inspec train dataset...\")\n",
    "inspec_train_results, inspec_train_metrics = process_inspec(inspec_ds['train'], model, top_n=8)\n",
    "\n",
    "print(\"Processing Inspec test dataset...\")\n",
    "inspec_test_results, inspec_test_metrics = process_inspec(inspec_ds['test'], model, top_n=8)\n",
    "\n",
    "print(\"\\nInspec Metrics:\")\n",
    "print(f\"Train - Precision: {inspec_train_metrics['precision']:.3f}, Recall: {inspec_train_metrics['recall']:.3f}, F1: {inspec_train_metrics['f1']:.3f}\")\n",
    "print(f\"Test  - Precision: {inspec_test_metrics['precision']:.3f}, Recall: {inspec_test_metrics['recall']:.3f}, F1: {inspec_test_metrics['f1']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179932ee-b65d-484c-a8fb-5279f613b52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
